{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Hangman Game\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import random\n",
    "import string\n",
    "import secrets\n",
    "import time\n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "import torch\n",
    "from urllib.parse import parse_qs\n",
    "\n",
    "try:\n",
    "    from urllib.parse import parse_qs, urlencode, urlparse\n",
    "except ImportError:\n",
    "    from urlparse import parse_qs, urlparse\n",
    "    from urllib import urlencode\n",
    "\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# from nltk.corpus import words as nltk_words\n",
    "\n",
    "# def load_words_with_nltk(filepath, output_filepath=\"words_nltk_filtered.txt\"):\n",
    "#     \"\"\"\n",
    "#     Loads words, cleans them, and uses the NLTK library's word corpus\n",
    "#     to filter for real English words. The cleaned list is then saved.\n",
    "#     \"\"\"\n",
    "#     # Create a set of valid English words from the NLTK corpus for fast lookups.\n",
    "#     print(\"Loading NLTK English word corpus...\")\n",
    "#     valid_english_words = set(nltk_words.words())\n",
    "    \n",
    "#     with open(filepath, 'r', encoding='utf-8') as f:\n",
    "#         word_list = f.readlines()\n",
    "\n",
    "#     # --- Step 1: Initial Cleaning ---\n",
    "#     print(\"Performing initial cleaning...\")\n",
    "#     cleaned_words = [re.sub(r'[^a-z]', '', word.lower().strip()) for word in word_list]\n",
    "#     unique_words = set(word for word in cleaned_words if len(word) > 1)\n",
    "    \n",
    "#     # --- Step 2: Filter Using the NLTK Word List ---\n",
    "#     print(f\"Checking {len(unique_words)} unique words against the NLTK dictionary...\")\n",
    "#     final_words = sorted([word for word in unique_words if word in valid_english_words])\n",
    "    \n",
    "#     # --- Step 3: Save the Final Words to a File ---\n",
    "#     print(f\"\\nFound {len(final_words)} real words. Saving them to {output_filepath}...\")\n",
    "#     with open(output_filepath, 'w', encoding='utf-8') as f_out:\n",
    "#         for word in final_words:\n",
    "#             f_out.write(word + \"\\n\")\n",
    "#     print(\"File saved successfully.\")\n",
    "\n",
    "#     return final_words\n",
    "\n",
    "# # --- How to use it ---\n",
    "# # This will create your new, highly accurate word list for training.\n",
    "# DATA_PATH = 'words_250000_train.txt'\n",
    "# filtered_list = load_words_with_nltk(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import collections\n",
    "from urllib.parse import parse_qs\n",
    "\n",
    "# --- 1. Data Loading and Preprocessing ---\n",
    "def load_words(filepath):\n",
    "    \"\"\"Loads and cleans words from a file.\"\"\"\n",
    "    # Create a dummy file if it doesn't exist for demonstration\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"File '{filepath}' not found. Creating a dummy word file.\")\n",
    "        dummy_words = ['apple', 'banana', 'orange', 'grape', 'strawberry', 'blueberry', 'python', 'pytorch', 'tensor', 'notebook']\n",
    "        with open(filepath, 'w') as f:\n",
    "            for word in dummy_words:\n",
    "                f.write(word + '\\n')\n",
    "\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        words = f.readlines()\n",
    "    # Clean words: lowercase, strip whitespace, remove non-alpha characters\n",
    "    words = [re.sub(r'[^a-z]', '', word.lower().strip()) for word in words]\n",
    "    # Filter out very short words or empty strings resulting from cleaning\n",
    "    words = [word for word in words if len(word) > 1]\n",
    "    return words\n",
    "\n",
    "def create_char_mappings():\n",
    "    \"\"\"Creates character to index and index to character mappings.\"\"\"\n",
    "    all_chars = string.ascii_lowercase + '_#' # '#' is our padding token\n",
    "    char_to_idx = {char: i for i, char in enumerate(all_chars)}\n",
    "    idx_to_char = {i: char for i, char in enumerate(all_chars)}\n",
    "    vocab_size = len(all_chars)\n",
    "    mask_token_idx = char_to_idx['_']\n",
    "    padding_idx = char_to_idx['#']\n",
    "    return char_to_idx, idx_to_char, vocab_size, mask_token_idx, padding_idx\n",
    "\n",
    "# --- 2. Dataset and Dataloader Preparation ---\n",
    "\n",
    "class MaskedWordDataset(Dataset):\n",
    "    \"\"\"Generates a randomly masked version of a word on-the-fly.\"\"\"\n",
    "    def __init__(self, word_list, char_to_idx, mask_token_idx):\n",
    "        self.word_list = word_list\n",
    "        self.char_to_idx = char_to_idx\n",
    "        self.mask_token_idx = mask_token_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        word = self.word_list[idx]\n",
    "        word_indices = torch.tensor([self.char_to_idx[char] for char in word], dtype=torch.long)\n",
    "        n = len(word)\n",
    "        if n <= 2:\n",
    "            mask_positions = [random.randint(0, n - 1)]\n",
    "        else:\n",
    "            num_masks = random.randint(1, max(1, n - 1))\n",
    "            mask_positions = sorted(random.sample(range(n), num_masks))\n",
    "        input_word = word_indices.clone()\n",
    "        input_word[mask_positions] = self.mask_token_idx\n",
    "        target_word = torch.full_like(word_indices, -100) # ignore_index\n",
    "        target_word[mask_positions] = word_indices[mask_positions]\n",
    "        return input_word, target_word\n",
    "\n",
    "def pad_collate_fn(batch, padding_value):\n",
    "    \"\"\"Pads sequences in a batch.\"\"\"\n",
    "    inputs, targets = zip(*batch)\n",
    "    padded_inputs = pad_sequence(inputs, batch_first=True, padding_value=padding_value)\n",
    "    padded_targets = pad_sequence(targets, batch_first=True, padding_value=-100)\n",
    "    return padded_inputs, padded_targets\n",
    "\n",
    "# --- 3. Unified Training Loop ---\n",
    "\n",
    "def train_model(model, dataloader, optimizer, scheduler, criterion, device, num_epochs, model_path):\n",
    "    \"\"\"Trains a given model with gradient clipping.\"\"\"\n",
    "    model.train()\n",
    "    best_loss = float('inf')\n",
    "    print(f\"\\n--- Starting Training for {model.__class__.__name__} ---\")\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for inputs, targets in progress_bar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.view(-1, outputs.shape[2]), targets.view(-1))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            progress_bar.set_postfix({'Loss': loss.item()})\n",
    "        avg_epoch_loss = epoch_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1} Completed | Average Loss: {avg_epoch_loss:.4f}\")\n",
    "        scheduler.step(avg_epoch_loss)\n",
    "        if avg_epoch_loss < best_loss:\n",
    "            best_loss = avg_epoch_loss\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f\"Model improved and saved to {model_path} (Loss: {best_loss:.4f})\")\n",
    "    print(\"--- Training Finished ---\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining path of file*(change this to train the model on a different file)\n",
    "DATA_PATH = 'words_250000_train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Class: Positional Encoding (Used by BiLSTM and Transformer) ---\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=50):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# --- Model 1: BiLSTM Solver ---\n",
    "class BiLSTMSolver(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers, padding_idx, dropout=0.3):\n",
    "        super(BiLSTMSolver, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        self.pos_encoder = PositionalEncoding(embedding_dim, dropout)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim, hidden_dim, num_layers=n_layers,\n",
    "            bidirectional=True, batch_first=True, dropout=dropout if n_layers > 1 else 0\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim * 2, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x) * math.sqrt(self.embedding_dim)\n",
    "        pos_encoded = self.pos_encoder(embedded)\n",
    "        lstm_out, _ = self.lstm(pos_encoded)\n",
    "        return self.fc(lstm_out)\n",
    "\n",
    "# --- Model 2: Transformer Solver ---\n",
    "class TransformerSolver(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_heads, n_encoder_layers, dim_feedforward, padding_idx, dropout=0.3):\n",
    "        super(TransformerSolver, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        self.pos_encoder = PositionalEncoding(embedding_dim, dropout)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embedding_dim, nhead=n_heads,\n",
    "            dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_encoder_layers)\n",
    "        self.fc = nn.Linear(embedding_dim, vocab_size)\n",
    "        self.padding_idx = padding_idx\n",
    "\n",
    "    def forward(self, src):\n",
    "        src_key_padding_mask = (src == self.padding_idx)\n",
    "        embedded = self.embedding(src) * math.sqrt(self.embedding_dim)\n",
    "        pos_encoded = self.pos_encoder(embedded)\n",
    "        transformer_out = self.transformer_encoder(pos_encoded, src_key_padding_mask=src_key_padding_mask)\n",
    "        return self.fc(transformer_out)\n",
    "\n",
    "# --- Model 3: CharCNN Solver ---\n",
    "class CharCNNSolver(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_filters, kernel_sizes, padding_idx, dropout=0.5):\n",
    "        super(CharCNNSolver, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=embedding_dim, out_channels=num_filters, kernel_size=k)\n",
    "            for k in kernel_sizes\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(len(kernel_sizes) * num_filters, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x).permute(0, 2, 1)\n",
    "        conved = [torch.relu(conv(embedded)) for conv in self.convs]\n",
    "        pooled = [torch.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "        # Repeat output for each position to maintain a consistent output shape\n",
    "        return self.fc(cat).unsqueeze(1).repeat(1, x.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Training for BiLSTMSolver ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 444/444 [01:34<00:00,  4.72it/s, Loss=2.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Completed | Average Loss: 2.4847\n",
      "Model improved and saved to best_bilstm_solver.pth (Loss: 2.4847)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  35%|███▍      | 154/444 [00:33<01:02,  4.62it/s, Loss=2.28]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(optimizer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# --- Run Training ---\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbilstm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODEL_PATH_BILSTM\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 100\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, optimizer, scheduler, criterion, device, num_epochs, model_path)\u001b[0m\n\u001b[1;32m     98\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     99\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 100\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     progress_bar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m: loss\u001b[38;5;241m.\u001b[39mitem()})\n\u001b[1;32m    102\u001b[0m avg_epoch_loss \u001b[38;5;241m=\u001b[39m epoch_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- BiLSTM Training Configuration ---\n",
    "MODEL_PATH_BILSTM = 'best_bilstm_solver.pth'\n",
    "TARGET_GPU_ID = 3\n",
    "\n",
    "# Hyperparameters\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 512\n",
    "NUM_EPOCHS = 50\n",
    "EMBEDDING_DIM = 768\n",
    "HIDDEN_DIM = 512\n",
    "N_LAYERS = 4\n",
    "DROPOUT = 0.4\n",
    "\n",
    "# --- Setup ---\n",
    "device = torch.device(f'cuda:{TARGET_GPU_ID}' if torch.cuda.is_available() else 'cpu')\n",
    "char_to_idx, _, vocab_size, mask_token_idx, padding_idx = create_char_mappings()\n",
    "all_words = load_words(DATA_PATH)\n",
    "train_dataset = MaskedWordDataset(all_words, char_to_idx, mask_token_idx)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    collate_fn=lambda b: pad_collate_fn(b, padding_idx),\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# --- Model Initialization ---\n",
    "bilstm_model = BiLSTMSolver(\n",
    "    vocab_size, EMBEDDING_DIM, HIDDEN_DIM, N_LAYERS, padding_idx, DROPOUT\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(bilstm_model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.2, patience=3)\n",
    "\n",
    "# --- Run Training ---\n",
    "train_model(bilstm_model, train_dataloader, optimizer, scheduler, criterion, device, NUM_EPOCHS, MODEL_PATH_BILSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Training for TransformerSolver ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60: 100%|██████████| 888/888 [02:05<00:00,  7.10it/s, Loss=2.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Completed | Average Loss: 2.8936\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.8936)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/60: 100%|██████████| 888/888 [02:06<00:00,  7.02it/s, Loss=2.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Completed | Average Loss: 2.8765\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.8765)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/60: 100%|██████████| 888/888 [02:06<00:00,  7.03it/s, Loss=2.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Completed | Average Loss: 2.8711\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.8711)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/60: 100%|██████████| 888/888 [02:06<00:00,  7.02it/s, Loss=2.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Completed | Average Loss: 2.8676\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.8676)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/60: 100%|██████████| 888/888 [02:06<00:00,  7.03it/s, Loss=2.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Completed | Average Loss: 2.8657\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.8657)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/60: 100%|██████████| 888/888 [02:06<00:00,  7.03it/s, Loss=2.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Completed | Average Loss: 2.8649\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.8649)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/60: 100%|██████████| 888/888 [02:06<00:00,  7.02it/s, Loss=2.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Completed | Average Loss: 2.8636\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.8636)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/60: 100%|██████████| 888/888 [02:06<00:00,  7.04it/s, Loss=2.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Completed | Average Loss: 2.8619\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.8619)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/60: 100%|██████████| 888/888 [02:06<00:00,  7.02it/s, Loss=2.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Completed | Average Loss: 2.8583\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.8583)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/60: 100%|██████████| 888/888 [02:06<00:00,  7.03it/s, Loss=2.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Completed | Average Loss: 2.8560\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.8560)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/60: 100%|██████████| 888/888 [02:06<00:00,  7.03it/s, Loss=2.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Completed | Average Loss: 2.8522\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.8522)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/60: 100%|██████████| 888/888 [02:06<00:00,  7.03it/s, Loss=2.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Completed | Average Loss: 2.8506\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.8506)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/60: 100%|██████████| 888/888 [02:06<00:00,  7.04it/s, Loss=2.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Completed | Average Loss: 2.8477\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.8477)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/60: 100%|██████████| 888/888 [02:06<00:00,  7.02it/s, Loss=2.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Completed | Average Loss: 2.8452\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.8452)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/60: 100%|██████████| 888/888 [02:06<00:00,  7.04it/s, Loss=2.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Completed | Average Loss: 2.8415\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.8415)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/60: 100%|██████████| 888/888 [02:06<00:00,  7.02it/s, Loss=2.8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Completed | Average Loss: 2.8359\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.8359)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/60: 100%|██████████| 888/888 [02:06<00:00,  7.03it/s, Loss=2.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Completed | Average Loss: 2.8300\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.8300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/60: 100%|██████████| 888/888 [02:06<00:00,  7.04it/s, Loss=2.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Completed | Average Loss: 2.8215\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.8215)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/60: 100%|██████████| 888/888 [02:05<00:00,  7.05it/s, Loss=2.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Completed | Average Loss: 2.8119\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.8119)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/60: 100%|██████████| 888/888 [02:06<00:00,  7.03it/s, Loss=2.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Completed | Average Loss: 2.8033\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.8033)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/60: 100%|██████████| 888/888 [02:06<00:00,  7.02it/s, Loss=2.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Completed | Average Loss: 2.7953\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.7953)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/60: 100%|██████████| 888/888 [02:05<00:00,  7.06it/s, Loss=2.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Completed | Average Loss: 2.7865\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.7865)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/60: 100%|██████████| 888/888 [02:06<00:00,  7.03it/s, Loss=2.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Completed | Average Loss: 2.7769\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.7769)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/60: 100%|██████████| 888/888 [02:06<00:00,  7.03it/s, Loss=2.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Completed | Average Loss: 2.7684\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.7684)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/60: 100%|██████████| 888/888 [02:06<00:00,  7.03it/s, Loss=2.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Completed | Average Loss: 2.7591\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.7591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/60: 100%|██████████| 888/888 [02:06<00:00,  7.00it/s, Loss=2.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Completed | Average Loss: 2.7494\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.7494)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/60: 100%|██████████| 888/888 [02:06<00:00,  7.03it/s, Loss=2.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Completed | Average Loss: 2.7387\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.7387)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/60: 100%|██████████| 888/888 [02:06<00:00,  7.04it/s, Loss=2.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Completed | Average Loss: 2.7265\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.7265)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/60: 100%|██████████| 888/888 [02:06<00:00,  7.04it/s, Loss=2.73]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Completed | Average Loss: 2.7126\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.7126)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/60: 100%|██████████| 888/888 [02:06<00:00,  7.02it/s, Loss=2.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Completed | Average Loss: 2.7018\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.7018)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/60: 100%|██████████| 888/888 [02:06<00:00,  7.01it/s, Loss=2.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Completed | Average Loss: 2.6896\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.6896)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/60: 100%|██████████| 888/888 [02:06<00:00,  7.04it/s, Loss=2.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Completed | Average Loss: 2.6780\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.6780)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/60: 100%|██████████| 888/888 [02:06<00:00,  7.02it/s, Loss=2.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Completed | Average Loss: 2.6663\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.6663)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/60: 100%|██████████| 888/888 [02:06<00:00,  7.02it/s, Loss=2.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Completed | Average Loss: 2.6539\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.6539)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/60: 100%|██████████| 888/888 [02:06<00:00,  7.03it/s, Loss=2.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Completed | Average Loss: 2.6431\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.6431)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/60: 100%|██████████| 888/888 [02:06<00:00,  7.02it/s, Loss=2.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Completed | Average Loss: 2.6296\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.6296)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/60: 100%|██████████| 888/888 [02:06<00:00,  7.02it/s, Loss=2.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Completed | Average Loss: 2.6180\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.6180)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/60: 100%|██████████| 888/888 [02:05<00:00,  7.05it/s, Loss=2.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Completed | Average Loss: 2.6045\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.6045)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/60: 100%|██████████| 888/888 [02:06<00:00,  7.03it/s, Loss=2.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Completed | Average Loss: 2.5885\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.5885)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/60: 100%|██████████| 888/888 [02:06<00:00,  7.03it/s, Loss=2.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Completed | Average Loss: 2.5755\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.5755)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/60: 100%|██████████| 888/888 [02:06<00:00,  7.04it/s, Loss=2.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Completed | Average Loss: 2.5608\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.5608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/60: 100%|██████████| 888/888 [02:05<00:00,  7.06it/s, Loss=2.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Completed | Average Loss: 2.5444\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.5444)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/60: 100%|██████████| 888/888 [02:06<00:00,  7.04it/s, Loss=2.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Completed | Average Loss: 2.5315\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.5315)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/60: 100%|██████████| 888/888 [02:06<00:00,  7.01it/s, Loss=2.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Completed | Average Loss: 2.5156\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.5156)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/60: 100%|██████████| 888/888 [02:06<00:00,  7.02it/s, Loss=2.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Completed | Average Loss: 2.5011\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.5011)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/60: 100%|██████████| 888/888 [02:06<00:00,  7.03it/s, Loss=2.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Completed | Average Loss: 2.4859\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.4859)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/60: 100%|██████████| 888/888 [02:06<00:00,  7.04it/s, Loss=2.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Completed | Average Loss: 2.4715\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.4715)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/60: 100%|██████████| 888/888 [02:05<00:00,  7.05it/s, Loss=2.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Completed | Average Loss: 2.4595\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.4595)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/60: 100%|██████████| 888/888 [02:05<00:00,  7.06it/s, Loss=2.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Completed | Average Loss: 2.4441\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.4441)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/60: 100%|██████████| 888/888 [02:06<00:00,  7.03it/s, Loss=2.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Completed | Average Loss: 2.4315\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.4315)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/60: 100%|██████████| 888/888 [02:06<00:00,  7.03it/s, Loss=2.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Completed | Average Loss: 2.4184\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.4184)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/60: 100%|██████████| 888/888 [02:06<00:00,  7.04it/s, Loss=2.4] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Completed | Average Loss: 2.4069\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.4069)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/60: 100%|██████████| 888/888 [02:05<00:00,  7.05it/s, Loss=2.4] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Completed | Average Loss: 2.3945\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.3945)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/60: 100%|██████████| 888/888 [02:06<00:00,  7.04it/s, Loss=2.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Completed | Average Loss: 2.3829\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.3829)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/60: 100%|██████████| 888/888 [02:05<00:00,  7.06it/s, Loss=2.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Completed | Average Loss: 2.3719\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.3719)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/60: 100%|██████████| 888/888 [02:06<00:00,  7.04it/s, Loss=2.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Completed | Average Loss: 2.3642\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.3642)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/60: 100%|██████████| 888/888 [02:06<00:00,  7.04it/s, Loss=2.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Completed | Average Loss: 2.3553\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.3553)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/60: 100%|██████████| 888/888 [02:06<00:00,  7.03it/s, Loss=2.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Completed | Average Loss: 2.3474\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.3474)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/60: 100%|██████████| 888/888 [02:06<00:00,  7.02it/s, Loss=2.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Completed | Average Loss: 2.3406\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.3406)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/60: 100%|██████████| 888/888 [02:06<00:00,  7.04it/s, Loss=2.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Completed | Average Loss: 2.3347\n",
      "Model improved and saved to best_transformer_solver.pth (Loss: 2.3347)\n",
      "--- Training Finished ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Transformer Training Configuration ---\n",
    "MODEL_PATH_TRANSFORMER = 'best_transformer_solver.pth'\n",
    "TARGET_GPU_ID = 3 # Or a different GPU if you have one\n",
    "\n",
    "# Hyperparameters\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 256 # Transformers might need smaller batch sizes\n",
    "NUM_EPOCHS = 60\n",
    "EMBEDDING_DIM = 768\n",
    "N_HEADS = 12\n",
    "N_LAYERS = 6\n",
    "DIM_FEEDFORWARD = 1024\n",
    "DROPOUT = 0.2\n",
    "\n",
    "# --- Setup ---\n",
    "device = torch.device(f'cuda:{TARGET_GPU_ID}' if torch.cuda.is_available() else 'cpu')\n",
    "char_to_idx, _, vocab_size, mask_token_idx, padding_idx = create_char_mappings()\n",
    "all_words = load_words(DATA_PATH)\n",
    "train_dataset = MaskedWordDataset(all_words, char_to_idx, mask_token_idx)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    collate_fn=lambda b: pad_collate_fn(b, padding_idx),\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# --- Model Initialization ---\n",
    "transformer_model = TransformerSolver(\n",
    "    vocab_size, EMBEDDING_DIM, N_HEADS, N_LAYERS, DIM_FEEDFORWARD, padding_idx, DROPOUT\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(transformer_model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.2, patience=3)\n",
    "\n",
    "# --- Run Training ---\n",
    "train_model(transformer_model, train_dataloader, optimizer, scheduler, criterion, device, NUM_EPOCHS, MODEL_PATH_TRANSFORMER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Training for CharCNNSolver ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 444/444 [00:22<00:00, 20.13it/s, Loss=2.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Completed | Average Loss: 2.8944\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8944)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 444/444 [00:21<00:00, 20.18it/s, Loss=2.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Completed | Average Loss: 2.8586\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8586)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 444/444 [00:21<00:00, 20.27it/s, Loss=2.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Completed | Average Loss: 2.8530\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8530)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 444/444 [00:21<00:00, 20.19it/s, Loss=2.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Completed | Average Loss: 2.8481\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8481)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 444/444 [00:21<00:00, 20.21it/s, Loss=2.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Completed | Average Loss: 2.8446\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8446)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 444/444 [00:22<00:00, 20.18it/s, Loss=2.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Completed | Average Loss: 2.8419\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8419)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 444/444 [00:22<00:00, 20.17it/s, Loss=2.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Completed | Average Loss: 2.8409\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8409)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 444/444 [00:21<00:00, 20.19it/s, Loss=2.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Completed | Average Loss: 2.8378\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8378)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 444/444 [00:21<00:00, 20.20it/s, Loss=2.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Completed | Average Loss: 2.8355\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8355)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 444/444 [00:21<00:00, 20.23it/s, Loss=2.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Completed | Average Loss: 2.8340\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8340)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 444/444 [00:21<00:00, 20.19it/s, Loss=2.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Completed | Average Loss: 2.8337\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8337)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 444/444 [00:22<00:00, 20.05it/s, Loss=2.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Completed | Average Loss: 2.8317\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8317)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|██████████| 444/444 [00:22<00:00, 20.13it/s, Loss=2.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Completed | Average Loss: 2.8311\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8311)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|██████████| 444/444 [00:22<00:00, 20.06it/s, Loss=2.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Completed | Average Loss: 2.8303\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8303)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|██████████| 444/444 [00:22<00:00, 20.10it/s, Loss=2.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Completed | Average Loss: 2.8275\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8275)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|██████████| 444/444 [00:22<00:00, 20.09it/s, Loss=2.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Completed | Average Loss: 2.8281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|██████████| 444/444 [00:22<00:00, 20.09it/s, Loss=2.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Completed | Average Loss: 2.8272\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8272)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|██████████| 444/444 [00:22<00:00, 20.12it/s, Loss=2.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Completed | Average Loss: 2.8267\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8267)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|██████████| 444/444 [00:22<00:00, 20.03it/s, Loss=2.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Completed | Average Loss: 2.8255\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8255)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|██████████| 444/444 [00:22<00:00, 20.12it/s, Loss=2.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Completed | Average Loss: 2.8248\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8248)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|██████████| 444/444 [00:22<00:00, 20.09it/s, Loss=2.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Completed | Average Loss: 2.8236\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8236)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|██████████| 444/444 [00:22<00:00, 20.12it/s, Loss=2.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Completed | Average Loss: 2.8227\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8227)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|██████████| 444/444 [00:22<00:00, 20.11it/s, Loss=2.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Completed | Average Loss: 2.8216\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8216)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|██████████| 444/444 [00:22<00:00, 20.03it/s, Loss=2.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Completed | Average Loss: 2.8221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|██████████| 444/444 [00:22<00:00, 20.08it/s, Loss=2.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Completed | Average Loss: 2.8212\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8212)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|██████████| 444/444 [00:22<00:00, 20.06it/s, Loss=2.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Completed | Average Loss: 2.8222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|██████████| 444/444 [00:22<00:00, 20.18it/s, Loss=2.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Completed | Average Loss: 2.8210\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8210)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|██████████| 444/444 [00:22<00:00, 20.07it/s, Loss=2.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Completed | Average Loss: 2.8201\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8201)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|██████████| 444/444 [00:22<00:00, 20.11it/s, Loss=2.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Completed | Average Loss: 2.8193\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8193)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|██████████| 444/444 [00:22<00:00, 20.16it/s, Loss=2.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Completed | Average Loss: 2.8198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|██████████| 444/444 [00:22<00:00, 20.13it/s, Loss=2.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Completed | Average Loss: 2.8191\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8191)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: 100%|██████████| 444/444 [00:22<00:00, 20.14it/s, Loss=2.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Completed | Average Loss: 2.8189\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8189)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: 100%|██████████| 444/444 [00:21<00:00, 20.23it/s, Loss=2.8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Completed | Average Loss: 2.8191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: 100%|██████████| 444/444 [00:21<00:00, 20.21it/s, Loss=2.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Completed | Average Loss: 2.8176\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8176)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: 100%|██████████| 444/444 [00:21<00:00, 20.21it/s, Loss=2.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Completed | Average Loss: 2.8176\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8176)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: 100%|██████████| 444/444 [00:22<00:00, 20.10it/s, Loss=2.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Completed | Average Loss: 2.8175\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8175)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: 100%|██████████| 444/444 [00:22<00:00, 20.12it/s, Loss=2.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Completed | Average Loss: 2.8168\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8168)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: 100%|██████████| 444/444 [00:22<00:00, 20.14it/s, Loss=2.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Completed | Average Loss: 2.8154\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8154)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: 100%|██████████| 444/444 [00:22<00:00, 20.16it/s, Loss=2.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Completed | Average Loss: 2.8160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: 100%|██████████| 444/444 [00:22<00:00, 20.12it/s, Loss=2.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Completed | Average Loss: 2.8157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|██████████| 444/444 [00:22<00:00, 20.11it/s, Loss=2.8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Completed | Average Loss: 2.8149\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8149)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: 100%|██████████| 444/444 [00:21<00:00, 20.21it/s, Loss=2.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Completed | Average Loss: 2.8155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: 100%|██████████| 444/444 [00:21<00:00, 20.30it/s, Loss=2.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Completed | Average Loss: 2.8150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: 100%|██████████| 444/444 [00:21<00:00, 20.27it/s, Loss=2.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Completed | Average Loss: 2.8154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: 100%|██████████| 444/444 [00:21<00:00, 20.22it/s, Loss=2.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Completed | Average Loss: 2.8134\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8134)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: 100%|██████████| 444/444 [00:21<00:00, 20.19it/s, Loss=2.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Completed | Average Loss: 2.8140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: 100%|██████████| 444/444 [00:21<00:00, 20.21it/s, Loss=2.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Completed | Average Loss: 2.8140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|██████████| 444/444 [00:21<00:00, 20.38it/s, Loss=2.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Completed | Average Loss: 2.8124\n",
      "Model improved and saved to best_charcnn_solver.pth (Loss: 2.8124)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|██████████| 444/444 [00:21<00:00, 20.34it/s, Loss=2.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Completed | Average Loss: 2.8131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: 100%|██████████| 444/444 [00:21<00:00, 20.20it/s, Loss=2.81]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Completed | Average Loss: 2.8136\n",
      "--- Training Finished ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- CharCNN Training Configuration ---\n",
    "MODEL_PATH_CHARCNN = 'best_charcnn_solver.pth'\n",
    "TARGET_GPU_ID = 3 # Or a different GPU if you have one\n",
    "\n",
    "# Hyperparameters\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 512\n",
    "NUM_EPOCHS = 50\n",
    "EMBEDDING_DIM = 768\n",
    "NUM_FILTERS = 128\n",
    "KERNEL_SIZES = [2, 3, 4, 5]\n",
    "DROPOUT = 0.5\n",
    "\n",
    "# --- Setup ---\n",
    "device = torch.device(f'cuda:{TARGET_GPU_ID}' if torch.cuda.is_available() else 'cpu')\n",
    "char_to_idx, _, vocab_size, mask_token_idx, padding_idx = create_char_mappings()\n",
    "all_words = load_words(DATA_PATH)\n",
    "train_dataset = MaskedWordDataset(all_words, char_to_idx, mask_token_idx)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    collate_fn=lambda b: pad_collate_fn(b, padding_idx),\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# --- Model Initialization ---\n",
    "charcnn_model = CharCNNSolver(\n",
    "    vocab_size, EMBEDDING_DIM, NUM_FILTERS, KERNEL_SIZES, padding_idx, DROPOUT\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(charcnn_model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.2, patience=3)\n",
    "\n",
    "# --- Run Training ---\n",
    "train_model(charcnn_model, train_dataloader, optimizer, scheduler, criterion, device, NUM_EPOCHS, MODEL_PATH_CHARCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import collections\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "import os\n",
    "import json\n",
    "from urllib.parse import parse_qs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model import BiLSTMSolver, TransformerSolver, CharCNNSolver\n",
    "\n",
    "class HangmanAPI(object):\n",
    "    def __init__(self, access_token=None, session=None, timeout=None):\n",
    "        self.hangman_url = self.determine_hangman_url()\n",
    "        self.access_token = access_token\n",
    "        self.session = session or requests.Session()\n",
    "        self.timeout = timeout\n",
    "        self.guessed_letters = []\n",
    "        \n",
    "        # --- Ensemble Weights ---\n",
    "        self.W_BILSTM = 0.5\n",
    "        self.W_TRANSFORMER = 0.3\n",
    "        self.W_CHARCNN = 0.2\n",
    "\n",
    "        # --- Shared Parameters & Device ---\n",
    "        self.char_to_idx, self.idx_to_char, self.vocab_size, self.mask_token_idx, self.padding_idx = self._create_char_mappings()\n",
    "        TARGET_GPU_ID = 3 # You can change this ID\n",
    "        self.device = self._get_device(TARGET_GPU_ID)\n",
    "\n",
    "        # --- Load All Three Models ---\n",
    "        print(\"--- Initializing Ensemble Hangman Solver ---\")\n",
    "        self.bilstm_model = self._load_model('bilstm')\n",
    "        self.transformer_model = self._load_model('transformer')\n",
    "        self.charcnn_model = self._load_model('charcnn')\n",
    "        print(\"--- Initialization Complete ---\")\n",
    "\n",
    "    def _create_char_mappings(self):\n",
    "        \"\"\"Creates character-to-index mappings for the models.\"\"\"\n",
    "        all_chars = string.ascii_lowercase + '_#' # '_' is mask, '#' is padding\n",
    "        char_to_idx = {char: i for i, char in enumerate(all_chars)}\n",
    "        idx_to_char = {i: char for i, char in enumerate(all_chars)}\n",
    "        return char_to_idx, idx_to_char, len(all_chars), char_to_idx['_'], char_to_idx['#']\n",
    "        \n",
    "    def _get_device(self, gpu_id):\n",
    "        \"\"\"Selects the appropriate device (GPU or CPU) for PyTorch models.\"\"\"\n",
    "        if torch.cuda.is_available() and gpu_id < torch.cuda.device_count():\n",
    "            device = torch.device(f'cuda:{gpu_id}')\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "        print(f\"All models will be loaded onto device: {device}\")\n",
    "        return device\n",
    "\n",
    "    def _load_model(self, model_type):\n",
    "        \"\"\"Loads a specified pre-trained model.\"\"\"\n",
    "        MODEL_PATH = f'best_{model_type}_solver.pth'\n",
    "        if not os.path.exists(MODEL_PATH):\n",
    "            print(f\"Warning: Model file not found at {MODEL_PATH}. This model will be skipped.\")\n",
    "            return None\n",
    "        try:\n",
    "            if model_type == 'bilstm':\n",
    "                model = BiLSTMSolver(self.vocab_size, 768, 512, 4, self.padding_idx, dropout=0.4)\n",
    "            elif model_type == 'transformer':\n",
    "                model = TransformerSolver(self.vocab_size, 768, 12, 6, 1024, self.padding_idx, dropout=0.2)\n",
    "            elif model_type == 'charcnn':\n",
    "                model = CharCNNSolver(self.vocab_size, 768, 128, [2,3,4,5], self.padding_idx, dropout=0.5)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "            \n",
    "            state_dict = torch.load(MODEL_PATH, map_location=self.device)\n",
    "            model.load_state_dict(state_dict)\n",
    "            model.to(self.device)\n",
    "            model.eval()\n",
    "            print(f\"Successfully loaded {model_type} model from {MODEL_PATH}\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load {model_type} model from {MODEL_PATH}. Reason: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _get_aggregated_prediction(self, model, input_tensor):\n",
    "        \"\"\"Gets the probability distribution for letters in blank spaces from a model.\"\"\"\n",
    "        if model is None: return None\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            # Apply softmax to get probabilities\n",
    "            probabilities = torch.softmax(output, dim=2)[0]\n",
    "            \n",
    "            # Identify blank positions in the original word\n",
    "            clean_word = \"\".join([self.idx_to_char[idx.item()] for idx in input_tensor[0] if idx.item() != self.padding_idx])\n",
    "            blank_indices = [i for i, char in enumerate(clean_word) if char == '_']\n",
    "            \n",
    "            if not blank_indices: return torch.zeros(self.vocab_size, device=self.device)\n",
    "            \n",
    "            # Get probabilities only at blank positions\n",
    "            blank_probs = probabilities[blank_indices]\n",
    "            \n",
    "            prob_not_in_any_blank = torch.prod(1 - blank_probs, dim=0)\n",
    "            return 1 - prob_not_in_any_blank\n",
    "\n",
    "    ################################################\n",
    "    # Implemented your \"guess\" function here       #\n",
    "    ################################################\n",
    "    def guess(self, word):\n",
    "        clean_word = word.replace(\" \", \"\")\n",
    "        input_indices = [self.char_to_idx.get(c, self.mask_token_idx) for c in clean_word]\n",
    "        input_tensor = torch.tensor([input_indices], dtype=torch.long).to(self.device)\n",
    "\n",
    "        seq_len = input_tensor.shape[1]\n",
    "        MAX_KERNEL_SIZE = 5 \n",
    "        if seq_len < MAX_KERNEL_SIZE:\n",
    "            padding_needed = MAX_KERNEL_SIZE - seq_len\n",
    "            padding = torch.full((1, padding_needed), self.padding_idx, dtype=torch.long, device=self.device)\n",
    "            input_tensor = torch.cat([input_tensor, padding], dim=1)\n",
    "\n",
    "        # 3. Get predictions from all available models\n",
    "        bilstm_probs = self._get_aggregated_prediction(self.bilstm_model, input_tensor)\n",
    "        transformer_probs = self._get_aggregated_prediction(self.transformer_model, input_tensor)\n",
    "        charcnn_probs = self._get_aggregated_prediction(self.charcnn_model, input_tensor)\n",
    "        \n",
    "        # 4. Combine predictions using ensemble weights\n",
    "        final_probs = torch.zeros(self.vocab_size, device=self.device)\n",
    "        total_weight = 0\n",
    "        \n",
    "        if bilstm_probs is not None:\n",
    "            final_probs += self.W_BILSTM * bilstm_probs\n",
    "            total_weight += self.W_BILSTM\n",
    "        if transformer_probs is not None:\n",
    "            final_probs += self.W_TRANSFORMER * transformer_probs\n",
    "            total_weight += self.W_TRANSFORMER\n",
    "        if charcnn_probs is not None:\n",
    "            final_probs += self.W_CHARCNN * charcnn_probs\n",
    "            total_weight += self.W_CHARCNN\n",
    "\n",
    "        # 5. Handle case where no models are loaded\n",
    "        if total_weight < 1e-5:\n",
    "            print(\"Warning: No models were loaded. Using basic fallback guess.\")\n",
    "            # Fallback to guessing most common letters in English\n",
    "            return next((c for c in \"etaoinshrdlu\" if c not in self.guessed_letters), 'e')\n",
    "\n",
    "        # 6. Normalize probabilities and mask already guessed letters\n",
    "        final_probs /= total_weight\n",
    "        \n",
    "        for letter in self.guessed_letters:\n",
    "            if letter in self.char_to_idx:\n",
    "                final_probs[self.char_to_idx[letter]] = -1.0 # Set to a low value to avoid being picked\n",
    "\n",
    "        # 7. Return the letter with the highest probability\n",
    "        best_guess_idx = torch.argmax(final_probs).item()\n",
    "        return self.idx_to_char[best_guess_idx]\n",
    "\n",
    "    ##########################################################\n",
    "    # You'll likely not need to modify any of the code below #\n",
    "    ##########################################################\n",
    "    \n",
    "    @staticmethod\n",
    "    def determine_hangman_url():\n",
    "        links = ['https://trexsim.com']\n",
    "        data = {link: 0 for link in links}\n",
    "        for link in links:\n",
    "            requests.get(link)\n",
    "            for i in range(10):\n",
    "                s = time.time()\n",
    "                requests.get(link)\n",
    "                data[link] = time.time() - s\n",
    "        link = sorted(data.items(), key=lambda x: x[1])[0][0]\n",
    "        link += '/trexsim/hangman'\n",
    "        return link\n",
    "            \n",
    "    def start_game(self, practice=True, verbose=True):\n",
    "        # Reset guessed letters to empty set\n",
    "        self.guessed_letters = []\n",
    "                                \n",
    "        response = self.request(\"/new_game\", {\"practice\":practice})\n",
    "        if response.get('status')==\"approved\":\n",
    "            game_id = response.get('game_id')\n",
    "            word = response.get('word')\n",
    "            tries_remains = response.get('tries_remains')\n",
    "            if verbose:\n",
    "                print(\"Successfully started a new game! Game ID: {0}. # of tries remaining: {1}. Word: {2}.\".format(game_id, tries_remains, word))\n",
    "            while tries_remains>0:\n",
    "                # Get guessed letter from user code\n",
    "                guess_letter = self.guess(word)\n",
    "                        \n",
    "                # Append guessed letter to guessed letters field in hangman object\n",
    "                self.guessed_letters.append(guess_letter)\n",
    "                if verbose:\n",
    "                    print(\"Guessed letters: {}\".format(self.guessed_letters))\n",
    "                    print(\"Guessing letter: {0}\".format(guess_letter))\n",
    "                    \n",
    "                try:    \n",
    "                    res = self.request(\"/guess_letter\", {\"request\":\"guess_letter\", \"game_id\":game_id, \"letter\":guess_letter})\n",
    "                except HangmanAPIError:\n",
    "                    print('HangmanAPIError exception caught on request.')\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print('Other exception caught on request.')\n",
    "                    raise e\n",
    "                \n",
    "                if verbose:\n",
    "                    print(\"Server response: {0}\".format(res))\n",
    "                status = res.get('status')\n",
    "                tries_remains = res.get('tries_remains')\n",
    "                if status==\"success\":\n",
    "                    if verbose:\n",
    "                        print(\"Successfully finished game: {0}\".format(game_id))\n",
    "                    return True\n",
    "                elif status==\"failed\":\n",
    "                    reason = res.get('reason', '# of tries exceeded!')\n",
    "                    if verbose:\n",
    "                        print(\"Failed game: {0}. Because of: {1}\".format(game_id, reason))\n",
    "                    return False\n",
    "                elif status==\"ongoing\":\n",
    "                    word = res.get('word')\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"Failed to start a new game\")\n",
    "        return status==\"success\"\n",
    "        \n",
    "    def my_status(self):\n",
    "        return self.request(\"/my_status\", {})\n",
    "    \n",
    "    def request(\n",
    "            self, path, args=None, post_args=None, method=None):\n",
    "        if args is None:\n",
    "            args = dict()\n",
    "        if post_args is not None:\n",
    "            method = \"POST\"\n",
    "\n",
    "        if self.access_token:\n",
    "            if post_args and \"access_token\" not in post_args:\n",
    "                post_args[\"access_token\"] = self.access_token\n",
    "            elif \"access_token\" not in args:\n",
    "                args[\"access_token\"] = self.access_token\n",
    "\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        num_retry, time_sleep = 50, 2\n",
    "        for it in range(num_retry):\n",
    "            try:\n",
    "                response = self.session.request(\n",
    "                    method or \"GET\",\n",
    "                    self.hangman_url + path,\n",
    "                    timeout=self.timeout,\n",
    "                    params=args,\n",
    "                    data=post_args,\n",
    "                    verify=False\n",
    "                )\n",
    "                break\n",
    "            except requests.HTTPError as e:\n",
    "                response = json.loads(e.read())\n",
    "                raise HangmanAPIError(response)\n",
    "            except requests.exceptions.SSLError as e:\n",
    "                if it + 1 == num_retry:\n",
    "                    raise\n",
    "                time.sleep(time_sleep)\n",
    "\n",
    "        headers = response.headers\n",
    "        if 'json' in headers['content-type']:\n",
    "            result = response.json()\n",
    "        elif \"access_token\" in parse_qs(response.text):\n",
    "            query_str = parse_qs(response.text)\n",
    "            if \"access_token\" in query_str:\n",
    "                result = {\"access_token\": query_str[\"access_token\"][0]}\n",
    "                if \"expires\" in query_str:\n",
    "                    result[\"expires\"] = query_str[\"expires\"][0]\n",
    "            else:\n",
    "                raise HangmanAPIError(response.json())\n",
    "        else:\n",
    "            raise HangmanAPIError('Maintype was not text, or querystring')\n",
    "\n",
    "        if result and isinstance(result, dict) and result.get(\"error\"):\n",
    "            raise HangmanAPIError(result)\n",
    "        return result\n",
    "    \n",
    "class HangmanAPIError(Exception):\n",
    "    def __init__(self, result):\n",
    "        self.result = result\n",
    "        self.code = None\n",
    "        try:\n",
    "            self.type = result[\"error_code\"]\n",
    "        except (KeyError, TypeError):\n",
    "            self.type = \"\"\n",
    "\n",
    "        try:\n",
    "            self.message = result[\"error_description\"]\n",
    "        except (KeyError, TypeError):\n",
    "            try:\n",
    "                self.message = result[\"error\"][\"message\"]\n",
    "                self.code = result[\"error\"].get(\"code\")\n",
    "                if not self.type:\n",
    "                    self.type = result[\"error\"].get(\"type\", \"\")\n",
    "            except (KeyError, TypeError):\n",
    "                try:\n",
    "                    self.message = result[\"error_msg\"]\n",
    "                except (KeyError, TypeError):\n",
    "                    self.message = result\n",
    "\n",
    "        Exception.__init__(self, self.message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hangman_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
